import streamlit as st
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
from openai import OpenAI

# è®¾ç½®é¡µé¢é…ç½®ï¼ˆå¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤ï¼‰
st.set_page_config(
    page_title="é¾™è™æ¦œåˆ†æçœ‹æ¿",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–å¤§æ•°å­—
def format_number(num):
    if pd.isna(num):
        return "0"
    num = float(num)
    if num >= 100000000:
        return f"{num / 100000000:.2f}äº¿"
    elif num >= 10000:
        return f"{num / 10000:.2f}ä¸‡"
    else:
        return f"{num:.2f}"

# æ ¸å¿ƒæ•°æ®è·å–å‡½æ•°ï¼ˆå¸¦ç¼“å­˜ï¼‰
@st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
def get_lhb_data(date_str):
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„é¾™è™æ¦œæ•°æ®
    è¿”å›: (detail_df, jg_df, yyb_df)
    """
    try:
        # 1. é¾™è™æ¦œè¯¦æƒ…
        detail_df = ak.stock_lhb_detail_em(start_date=date_str, end_date=date_str)
        if detail_df is None or detail_df.empty:
            return None, None, None
            
        # 2. æœºæ„æ•°æ®
        jg_df = ak.stock_lhb_jgmmtj_em(start_date=date_str, end_date=date_str)
        
        # 3. è¥ä¸šéƒ¨æ•°æ®ï¼ˆç”¨äºè®¡ç®—å¤–èµ„ï¼‰
        yyb_df = ak.stock_lhb_hyyyb_em(start_date=date_str, end_date=date_str)
        
        return detail_df, jg_df, yyb_df
    except Exception as e:
        st.error(f"è·å–æ•°æ®æ—¶å‡ºé”™: {e}")
        return None, None, None

# æ™ºèƒ½æ—¥æœŸå›æº¯
def find_latest_data():
    today = datetime.now()
    # å°è¯•å›æº¯æœ€è¿‘ 10 å¤©
    for i in range(10):
        check_date = today - timedelta(days=i)
        date_str = check_date.strftime("%Y%m%d")
        display_date = check_date.strftime("%Y-%m-%d")
        week_day = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][check_date.weekday()]
        
        # å°è¯•è·å–è¯¦æƒ…æ•°æ®æ¥åˆ¤æ–­æ˜¯å¦æœ‰æ•°æ®
        try:
            # è¿™é‡Œä¸ä½¿ç”¨ç¼“å­˜çš„å‡½æ•°ï¼Œå› ä¸ºè¦å¿«é€Ÿæ¢æµ‹
            # ä½†ä¸ºäº†é¿å…é¢‘ç¹è¯·æ±‚è¢«å°ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨ get_lhb_dataï¼Œå› ä¸ºå¦‚æœå¤±è´¥å®ƒè¿”å› None
            # ä¸è¿‡ get_lhb_data ä¼šè°ƒç”¨ä¸‰ä¸ªæ¥å£ï¼Œæœ‰ç‚¹é‡ã€‚
            # æˆ‘ä»¬å…ˆåªè°ƒä¸€ä¸ªè½»é‡çš„
            df = ak.stock_lhb_detail_em(start_date=date_str, end_date=date_str)
            if df is not None and not df.empty:
                return date_str, f"{display_date}ï¼ˆ{week_day}ï¼‰"
        except:
            pass
    
    return None, None

# ä¸»ç¨‹åº
def main():
    st.title("ğŸ“ˆ ä¸œæ–¹è´¢å¯Œé¾™è™æ¦œåˆ†æçœ‹æ¿")
    
    # 1. æ™ºèƒ½è·å–æ—¥æœŸ
    with st.spinner("æ­£åœ¨å¯»æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥æ•°æ®..."):
        date_str, date_display = find_latest_data()
    
    if not date_str:
        st.error("æœ€è¿‘10å¤©æ²¡æœ‰æ‰¾åˆ°é¾™è™æ¦œæ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åå†è¯•ã€‚")
        return

    st.success(f"å½“å‰å±•ç¤ºæ•°æ®æ—¥æœŸï¼š**{date_display}**")
    
    # 2. è·å–è¯¦ç»†æ•°æ®
    with st.spinner(f"æ­£åœ¨æŠ“å– {date_display} çš„è¯¦ç»†æ•°æ®..."):
        detail_df, jg_df, yyb_df = get_lhb_data(date_str)
    
    if detail_df is None:
        st.error("æ— æ³•è·å–è¯¦ç»†æ•°æ®ã€‚")
        return

    # 3. è®¡ç®—å…³é”®æŒ‡æ ‡
    # (1) ä¸Šæ¦œä¸ªè‚¡æ€»æ•°
    total_stocks = len(detail_df['ä»£ç '].unique())
    
    # (2) æœºæ„ä¹°å…¥æ€»é¢
    jg_buy_total = 0
    if jg_df is not None and not jg_df.empty:
        jg_buy_total = jg_df['æœºæ„ä¹°å…¥æ€»é¢'].sum()
        
    # (3) å¤–èµ„ä¹°å…¥æ€»é¢ (ç­›é€‰æ·±è‚¡é€š/æ²ªè‚¡é€š)
    waizi_buy_total = 0
    if yyb_df is not None and not yyb_df.empty:
        waizi_mask = yyb_df['è¥ä¸šéƒ¨åç§°'].str.contains('è‚¡é€š')
        waizi_buy_total = yyb_df[waizi_mask]['ä¹°å…¥æ€»é‡‘é¢'].sum()

    # 4. å±•ç¤ºå…³é”®æŒ‡æ ‡
    st.subheader("ğŸ“Š å¸‚åœºæ¦‚è§ˆ")
    col1, col2, col3 = st.columns(3)
    col1.metric("ä¸Šæ¦œä¸ªè‚¡", f"{total_stocks} åª")
    col2.metric("æœºæ„ä¹°å…¥", format_number(jg_buy_total))
    col3.metric("å¤–èµ„ä¹°å…¥", format_number(waizi_buy_total))
    
    st.markdown("---")
    
    # 5. æ¦œä¸€å¤§å“¥
    st.subheader("ğŸ‘‘ æ¦œä¸€å¤§å“¥")
    
    # æŒ‰å‡€ä¹°é¢æ’åº
    # æ³¨æ„ï¼š'é¾™è™æ¦œå‡€ä¹°é¢' å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å­—ï¼Œéœ€è¦å¤„ç†
    # AkShare è¿”å›çš„é€šå¸¸å·²ç»æ˜¯æ•°å­—ï¼Œæˆ–è€…æ˜¯ float64
    # ç¡®ä¿æ˜¯æ•°å­—
    if 'é¾™è™æ¦œå‡€ä¹°é¢' in detail_df.columns:
        detail_df['é¾™è™æ¦œå‡€ä¹°é¢'] = pd.to_numeric(detail_df['é¾™è™æ¦œå‡€ä¹°é¢'], errors='coerce')
        
    top1_stock = detail_df.sort_values(by='é¾™è™æ¦œå‡€ä¹°é¢', ascending=False).iloc[0]
    
    top1_name = top1_stock['åç§°']
    top1_code = top1_stock['ä»£ç ']
    top1_net_buy = top1_stock['é¾™è™æ¦œå‡€ä¹°é¢']
    top1_change = top1_stock['æ¶¨è·Œå¹…']
    top1_reason = top1_stock['ä¸Šæ¦œåŸå› ']
    
    st.info(
        f"**{top1_name}** ({top1_code})\n\n"
        f"ğŸ’° å‡€ä¹°å…¥ï¼š**{format_number(top1_net_buy)}**\n\n"
        f"ğŸ“ˆ æ¶¨è·Œå¹…ï¼š{top1_change}%\n\n"
        f"ğŸ“ ä¸Šæ¦œåŸå› ï¼š{top1_reason}"
    )
    
    st.markdown("---")
    
    # 6. æ¦œå•æ˜ç»†
    st.subheader("ğŸ“‹ å‡€ä¹°å…¥ TOP 10")
    
    # ç­›é€‰åˆ—å¹¶æ’åº
    display_cols = ['åç§°', 'ä»£ç ', 'æ”¶ç›˜ä»·', 'æ¶¨è·Œå¹…', 'é¾™è™æ¦œå‡€ä¹°é¢']
    # ç¡®ä¿åˆ—å­˜åœ¨
    actual_cols = [c for c in display_cols if c in detail_df.columns]
    
    top10_df = detail_df.sort_values(by='é¾™è™æ¦œå‡€ä¹°é¢', ascending=False).head(10)[actual_cols]
    
    # æ ¼å¼åŒ–æ˜¾ç¤º
    # ä¸ºäº†æ‰‹æœºç«¯å¥½çœ‹ï¼Œå¯ä»¥å°†å‡€ä¹°é¢æ ¼å¼åŒ–
    top10_show = top10_df.copy()
    top10_show['é¾™è™æ¦œå‡€ä¹°é¢'] = top10_show['é¾™è™æ¦œå‡€ä¹°é¢'].apply(format_number)
    
    # ä½¿ç”¨ dataframe å±•ç¤º
    st.dataframe(
        top10_show,
        use_container_width=True,
        hide_index=True,
        column_config={
            "åç§°": st.column_config.TextColumn("åç§°", width="medium"),
            "ä»£ç ": st.column_config.TextColumn("ä»£ç ", width="small"),
            "æ”¶ç›˜ä»·": st.column_config.NumberColumn("æ”¶ç›˜ä»·", format="%.2f"),
            "æ¶¨è·Œå¹…": st.column_config.NumberColumn("æ¶¨å¹…", format="%.2f%%"),
            "é¾™è™æ¦œå‡€ä¹°é¢": st.column_config.TextColumn("å‡€ä¹°å…¥", width="medium"),
        }
    )
    
    # åº•éƒ¨æç¤º
    st.caption("æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œç½‘ | æ•°æ®æ›´æ–°å¯èƒ½æœ‰å»¶è¿Ÿ")

    # --- AI æ·±åº¦åˆ†æåŠŸèƒ½ ---
    st.markdown("---")
    st.subheader("ğŸ¤– AI æ·±åº¦åˆ†æ")

    if st.button("å¼€å§‹ AI åˆ†æ", type="primary"):
        # 1. æ£€æŸ¥å¯†é’¥é…ç½®
        secrets_missing = False
        try:
            if "openai" not in st.secrets:
                secrets_missing = True
        except Exception:
            secrets_missing = True

        if secrets_missing:
            st.error("è¯·å…ˆé…ç½® OpenAI å¯†é’¥ï¼è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»º .streamlit/secrets.toml æ–‡ä»¶ã€‚")
            st.info("""
            **é…ç½®ç¤ºä¾‹ (.streamlit/secrets.toml):**
            ```toml
            [openai]
            api_key = "sk-..."
            base_url = "https://api.openai.com/v1"  # æˆ–å…¶ä»–å…¼å®¹çš„ Base URL
            ```
            """)
            return

        # 2. å‡†å¤‡æ•°æ®ç»™ AI
        # é€‰å– AI éœ€è¦çš„åˆ—
        ai_cols = ['åç§°', 'ä»£ç ', 'é¾™è™æ¦œå‡€ä¹°é¢', 'æ¶¨è·Œå¹…', 'æ¢æ‰‹ç‡']
        # ç¡®ä¿åˆ—éƒ½å­˜åœ¨ (æ¢æ‰‹ç‡å¯èƒ½åœ¨æŸäº›ç‰¹å®šæƒ…å†µä¸‹æ²¡æœ‰ï¼Œåšä¸ªå®¹é”™)
        existing_ai_cols = [c for c in ai_cols if c in detail_df.columns]
        
        ai_df = detail_df.sort_values(by='é¾™è™æ¦œå‡€ä¹°é¢', ascending=False).head(10)[existing_ai_cols]
        
        # é‡å‘½ååˆ—ä»¥èŠ‚çœ Token å¹¶è®© AI æ›´æ˜“è¯»
        ai_df = ai_df.rename(columns={
            'åç§°': 'è‚¡ç¥¨å', 
            'é¾™è™æ¦œå‡€ä¹°é¢': 'å‡€ä¹°å…¥',
            'æ¶¨è·Œå¹…': 'æ¶¨å¹…'
        })
        
        # è½¬æ¢ä¸º Markdown å­—ç¬¦ä¸²
        data_str = ai_df.to_markdown(index=False)

        # 3. æ„å»º Prompt
        system_prompt = """
        ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„ A è‚¡èµ„æ·±æ¸¸èµ„åˆ†æå¸ˆã€‚
        è¯·æ ¹æ®æä¾›çš„é¾™è™æ¦œå‡€ä¹°å…¥å‰ 10 åæ•°æ®ï¼Œå¯¹æ¯åªä¸Šæ¦œè‚¡ç¥¨è¿›è¡Œç®€çŸ­ç‚¹è¯„ï¼Œå¹¶åœ¨æœ€åç»™å‡ºå¸‚åœºæ€»ç»“ã€‚
        
        è¦æ±‚ï¼š
        1. é€ä¸ªç‚¹è¯„ï¼šå¯¹æ¯ä¸€åªè‚¡ç¥¨ï¼Œç”¨ä¸€å¥è¯ç‚¹è¯„å…¶èµ„é‡‘æ€§è´¨ï¼ˆæœºæ„/æ¸¸èµ„/æ•£æˆ·ï¼‰ã€æ¿å—åœ°ä½æˆ–æŠ€æœ¯å½¢æ€ã€‚
        2. å¸‚åœºæ€»ç»“ï¼šåœ¨ç‚¹è¯„å®Œæ‰€æœ‰è‚¡ç¥¨åï¼Œæ€»ç»“ä»Šæ—¥å¸‚åœºæƒ…ç»ªï¼ˆæƒ…ç»ªé«˜æ½®/åˆ†æ­§/é€€æ½®ï¼‰å’Œä¸»çº¿çƒ­ç‚¹ã€‚
        3. é£æ ¼çŠ€åˆ©ã€ç®€ç»ƒã€ä¸è¦è¯´åºŸè¯ã€‚
        4. ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºã€‚
        """

        user_prompt = f"""
        è¿™æ˜¯ä»Šæ—¥é¾™è™æ¦œå‡€ä¹°å…¥å‰ 10 åçš„æ•°æ®ï¼š
        {data_str}
        
        è¯·å¼€å§‹ä½ çš„åˆ†æï¼š
        """

        # 4. è°ƒç”¨ AI
        try:
            client = OpenAI(
                api_key=st.secrets["openai"]["api_key"],
                base_url=st.secrets["openai"]["base_url"]
            )
            
            with st.spinner('AI æ­£åœ¨åˆ†æé¾™è™æ¦œæ•°æ®ï¼Œè¯·ç¨å€™...'):
                # å°è¯•ä» secrets è·å–æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º gpt-3.5-turbo
                model_name = st.secrets["openai"].get("model", "gpt-3.5-turbo")
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7
                )
                
                analysis_result = response.choices[0].message.content
                
            st.success("åˆ†æå®Œæˆï¼")
            st.markdown("### ğŸ§  èµ„æ·±æ¸¸èµ„ç‚¹è¯„")
            st.info(analysis_result)
            
        except Exception as e:
            st.error(f"AI åˆ†æè¯·æ±‚å¤±è´¥: {e}")


if __name__ == "__main__":
    main()
